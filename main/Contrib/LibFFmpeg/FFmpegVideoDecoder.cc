// This file is part of RAVL, Recognition And Vision Library 
// Copyright (C) 2005, Omniperception Ltd.
// This code may be redistributed under the terms of the GNU Lesser
// General Public License (LGPL). See the lgpl.licence file for details or
// see http://www.gnu.org/copyleft/lesser.html
// file-header-ends-here
//! rcsid="$Id$"
//! lib=RavlLibFFmpeg

#include "Ravl/Image/FFmpegVideoDecoder.hh"
#include "Ravl/Exception.hh"

#define DODEBUG 1
#if DODEBUG
#define ONDEBUG(x) x
#else
#define ONDEBUG(x)
#endif

namespace RavlN {
  
  //: Constructor.
  
  FFmpegVideoDecoderBaseC::FFmpegVideoDecoderBaseC(DPISPortC<FFmpegPacketC> &_packetStream,IntT _videoStreamId,IntT _codecId) 
    : videoStreamId(-1),
      pCodecCtx(0),
      pFrame(0),
      bytesRemaining(0),
      rawData(0)
  {
    if(!Open(_packetStream,_videoStreamId,_codecId))
      throw ExceptionOperationFailedC("Failed to open video stream. ");
  }
  
  //: Default constructor.
  
  FFmpegVideoDecoderBaseC::FFmpegVideoDecoderBaseC() 
    : videoStreamId(-1),
      pCodecCtx(0),
      pFrame(0),
      bytesRemaining(0),
      rawData(0)
  {}

  //: Destructor.
  
  FFmpegVideoDecoderBaseC::~FFmpegVideoDecoderBaseC() {
    // Clean up codec
    if(pCodecCtx != 0)
      avcodec_close(pCodecCtx);
    if(pFrame != 0)
      av_free(pFrame);
  }
  
  //: Open a stream.
  
  bool FFmpegVideoDecoderBaseC::Open(DPISPortC<FFmpegPacketC> &packetStream,IntT _videoStreamId,IntT codecId) {
    if(pCodecCtx != 0) {
      cerr << "FFmpegVideoDecoderBaseC::Open, Stream already open. \n";
      return false;
    }
    input = packetStream;
    videoStreamId = _videoStreamId;
    
    // Get a pointer to the codec context for the video stream
    
    // Do we really need this, can't we get away with just using the codecId ?
    FFmpegPacketStreamC ps(packetStream);
    if(!ps.IsValid()) {
      cerr << "FFmpegVideoDecoderBaseC::Open, Unsupported packet stream type. \n";
      return false;      
    }
    pCodecCtx = &(ps.FormatCtx()->streams[videoStreamId]->codec);
    
    // Find the decoder for the video stream
    AVCodec *pCodec = avcodec_find_decoder(static_cast<CodecID>(codecId));
    if (pCodec == NULL) {
      cerr << "FFmpegVideoDecoderBaseC::Open, Failed to find codec. \n";
      return false;
    }
    
    ONDEBUG(cerr << "FFmpegPacketStreamBodyC::CheckForVideo codec found(" << (pCodec->name != NULL ? pCodec->name : "NULL") << ")" << endl);
    
    // Inform the codec that we can handle truncated bitstreams
    // i.e. bitstreams where frame boundaries can fall in the middle of packets
    if (pCodec->capabilities & CODEC_CAP_TRUNCATED)
      pCodecCtx->flags |= CODEC_FLAG_TRUNCATED;
    bool ret = false;
    
    // Open codec
    if (avcodec_open(pCodecCtx, pCodec) >= 0) {
      ONDEBUG(cerr << "FFmpegPacketStreamBodyC::CheckForVideo codec constructed ok. " << endl);
      ret = true;
    }
    
    // Hack to correct wrong frame rates that seem to be generated by some 
    // codecs
    if(pCodecCtx->frame_rate>1000 && pCodecCtx->frame_rate_base==1)
      pCodecCtx->frame_rate_base=1000;

    // Allocate a frame.
    pFrame=avcodec_alloc_frame();
    return true;
  }
  
  //: Decode the next frame.
  
  bool FFmpegVideoDecoderBaseC::DecodeFrame() {
    int             bytesDecoded;
    int             frameFinished;
    
    // Decode packets until we have decoded a complete frame
    while(true) {
      // Work on the current packet until we have decoded all of it
      while(bytesRemaining > 0) {
        // Decode the next chunk of data
        bytesDecoded=avcodec_decode_video(pCodecCtx, pFrame,
                                          &frameFinished, rawData, bytesRemaining);
        
        // Was there an error?
        if(bytesDecoded < 0) {
          cerr << "FFmpegVideoDecoderBaseC::DecodeFrame, Error while decoding frame. ";
          return false;
        }
        
        bytesRemaining -= bytesDecoded;
        rawData += bytesDecoded;
        
        // Did we finish the current frame? Then we can return
        if(frameFinished)
          return true;
      }
      
      // Read the next packet, skipping all packets that aren't for this
      // stream
      do {
        if(!input.Get(packet)) {
          // There can't be any more frames in the stream.
          return false; // Failed to find next packet.
        }
      } while(packet.StreamIndex() != videoStreamId);
      
      bytesRemaining = packet.Size();
      rawData = packet.Data();
    }
    
    return false;
  }
  
  //: Get a frame of video from stream.
  
  bool FFmpegVideoDecoderBaseC::GetFrame(ImageC<ByteRGBValueC> &frame) {
    if(!DecodeFrame())
      return false;
    AVFrame *pFrameRGB = avcodec_alloc_frame();
    // Determine required buffer size and allocate buffer
    IntT numBytes=avpicture_get_size(PIX_FMT_RGB24, pCodecCtx->width,pCodecCtx->height);
    uint8_t *buffer=new uint8_t[numBytes];
    avpicture_fill((AVPicture *)pFrameRGB, buffer, PIX_FMT_RGB24,pCodecCtx->width, pCodecCtx->height);
    img_convert((AVPicture *)pFrameRGB, PIX_FMT_RGB24, (AVPicture*)pFrame, pCodecCtx->pix_fmt, pCodecCtx->width, pCodecCtx->height);
    
    frame = ImageC<ByteRGBValueC>(pCodecCtx->height,pCodecCtx->width,static_cast<ByteRGBValueC *>((void *)buffer),true);
    av_free(pFrameRGB);
    
    return true;
  }
  
}
